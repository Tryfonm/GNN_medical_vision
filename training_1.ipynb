{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.main.graph_generation import main\n",
    "\n",
    "import numpy as numpy\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "from skimage.segmentation import slic\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Dataset\n",
    "\n",
    "from src.main.data import CustomGraphDataset\n",
    "\n",
    "dataset = CustomGraphDataset(root=\"data/processed/c0_03__s1000/\")\n",
    "# for data in dataset:\n",
    "#     print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[2533, 4], edge_index=[2, 49213], edge_attr=[49213, 1], y=[2533], batch=[2533], ptr=[5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 256)\n",
    "        self.conv2 = GCNConv(256, 16)\n",
    "        self.conv3 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        \n",
    "        x, edge_index, edge_attr = graph.x.to(torch.float), graph.edge_index.to(torch.int64), graph.edge_attr.to(torch.float)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# model_test = GCN(num_features=4, num_classes=4).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 74)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "for batch in dataloader:\n",
    "    all_labels.extend(batch.y.numpy())\n",
    "\n",
    "class_counts = Counter(all_labels)\n",
    "total_count = float(sum(class_counts.values()))\n",
    "class_weights = {cls: total_count / count for cls, count in class_counts.items()}\n",
    "weights = torch.tensor([class_weights[i] for i in range(4)], dtype=torch.float32).to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 1.374 | Train Accuracy: 0.4527 | Val Loss: 1.365 | Val Accuracy: 0.5065\n",
      "Epoch 10 | Train Loss: 1.219 | Train Accuracy: 0.7341 | Val Loss: 1.252 | Val Accuracy: 0.5416\n",
      "Epoch 20 | Train Loss: 1.207 | Train Accuracy: 0.6644 | Val Loss: 1.239 | Val Accuracy: 0.8274\n",
      "Epoch 30 | Train Loss: 1.200 | Train Accuracy: 0.7117 | Val Loss: 1.199 | Val Accuracy: 0.6747\n",
      "Epoch 40 | Train Loss: 1.186 | Train Accuracy: 0.7337 | Val Loss: 1.202 | Val Accuracy: 0.7521\n",
      "Epoch 50 | Train Loss: 1.184 | Train Accuracy: 0.6767 | Val Loss: 1.215 | Val Accuracy: 0.7861\n",
      "Epoch 60 | Train Loss: 1.176 | Train Accuracy: 0.6913 | Val Loss: 1.200 | Val Accuracy: 0.7719\n",
      "Epoch 70 | Train Loss: 1.177 | Train Accuracy: 0.6467 | Val Loss: 1.221 | Val Accuracy: 0.7875\n",
      "Epoch 80 | Train Loss: 1.167 | Train Accuracy: 0.7070 | Val Loss: 1.209 | Val Accuracy: 0.7885\n",
      "Epoch 90 | Train Loss: 1.159 | Train Accuracy: 0.7287 | Val Loss: 1.209 | Val Accuracy: 0.6938\n",
      "Epoch 100 | Train Loss: 1.154 | Train Accuracy: 0.6883 | Val Loss: 1.201 | Val Accuracy: 0.8322\n",
      "Epoch 110 | Train Loss: 1.134 | Train Accuracy: 0.7564 | Val Loss: 1.189 | Val Accuracy: 0.7890\n",
      "Epoch 120 | Train Loss: 1.144 | Train Accuracy: 0.7534 | Val Loss: 1.190 | Val Accuracy: 0.7749\n",
      "Epoch 130 | Train Loss: 1.125 | Train Accuracy: 0.7411 | Val Loss: 1.216 | Val Accuracy: 0.8178\n",
      "Epoch 140 | Train Loss: 1.136 | Train Accuracy: 0.6834 | Val Loss: 1.205 | Val Accuracy: 0.8424\n",
      "Epoch 150 | Train Loss: 1.124 | Train Accuracy: 0.7550 | Val Loss: 1.197 | Val Accuracy: 0.8147\n",
      "Epoch 160 | Train Loss: 1.126 | Train Accuracy: 0.7039 | Val Loss: 1.184 | Val Accuracy: 0.7856\n",
      "Epoch 170 | Train Loss: 1.107 | Train Accuracy: 0.7913 | Val Loss: 1.169 | Val Accuracy: 0.7728\n",
      "Epoch 180 | Train Loss: 1.101 | Train Accuracy: 0.7752 | Val Loss: 1.179 | Val Accuracy: 0.7907\n",
      "Epoch 190 | Train Loss: 1.125 | Train Accuracy: 0.7770 | Val Loss: 1.181 | Val Accuracy: 0.7630\n",
      "Epoch 200 | Train Loss: 1.092 | Train Accuracy: 0.7630 | Val Loss: 1.179 | Val Accuracy: 0.7516\n",
      "Epoch 210 | Train Loss: 1.114 | Train Accuracy: 0.8126 | Val Loss: 1.199 | Val Accuracy: 0.5932\n",
      "Epoch 220 | Train Loss: 1.090 | Train Accuracy: 0.7829 | Val Loss: 1.166 | Val Accuracy: 0.7613\n",
      "Epoch 230 | Train Loss: 1.081 | Train Accuracy: 0.8019 | Val Loss: 1.168 | Val Accuracy: 0.7496\n",
      "Epoch 240 | Train Loss: 1.086 | Train Accuracy: 0.7883 | Val Loss: 1.161 | Val Accuracy: 0.7730\n",
      "Epoch 250 | Train Loss: 1.090 | Train Accuracy: 0.7673 | Val Loss: 1.161 | Val Accuracy: 0.7504\n",
      "Epoch 260 | Train Loss: 1.073 | Train Accuracy: 0.7959 | Val Loss: 1.171 | Val Accuracy: 0.7188\n",
      "Epoch 270 | Train Loss: 1.079 | Train Accuracy: 0.7859 | Val Loss: 1.171 | Val Accuracy: 0.7865\n",
      "Epoch 280 | Train Loss: 1.065 | Train Accuracy: 0.7772 | Val Loss: 1.170 | Val Accuracy: 0.7738\n",
      "Epoch 290 | Train Loss: 1.056 | Train Accuracy: 0.7922 | Val Loss: 1.162 | Val Accuracy: 0.7997\n",
      "Epoch 300 | Train Loss: 1.077 | Train Accuracy: 0.7868 | Val Loss: 1.199 | Val Accuracy: 0.6383\n",
      "Epoch 310 | Train Loss: 1.055 | Train Accuracy: 0.7932 | Val Loss: 1.163 | Val Accuracy: 0.7614\n",
      "Epoch 320 | Train Loss: 1.065 | Train Accuracy: 0.7797 | Val Loss: 1.217 | Val Accuracy: 0.6768\n",
      "Epoch 330 | Train Loss: 1.074 | Train Accuracy: 0.7965 | Val Loss: 1.191 | Val Accuracy: 0.6489\n",
      "Epoch 340 | Train Loss: 1.056 | Train Accuracy: 0.7853 | Val Loss: 1.159 | Val Accuracy: 0.7424\n",
      "Epoch 350 | Train Loss: 1.053 | Train Accuracy: 0.7925 | Val Loss: 1.169 | Val Accuracy: 0.7275\n",
      "Epoch 360 | Train Loss: 1.052 | Train Accuracy: 0.7646 | Val Loss: 1.174 | Val Accuracy: 0.7530\n",
      "Epoch 370 | Train Loss: 1.028 | Train Accuracy: 0.7926 | Val Loss: 1.178 | Val Accuracy: 0.7417\n",
      "Epoch 380 | Train Loss: 1.036 | Train Accuracy: 0.7851 | Val Loss: 1.169 | Val Accuracy: 0.7539\n",
      "Epoch 390 | Train Loss: 1.057 | Train Accuracy: 0.7767 | Val Loss: 1.174 | Val Accuracy: 0.7539\n",
      "Epoch 400 | Train Loss: 1.034 | Train Accuracy: 0.7929 | Val Loss: 1.184 | Val Accuracy: 0.7113\n",
      "Epoch 410 | Train Loss: 1.027 | Train Accuracy: 0.7995 | Val Loss: 1.199 | Val Accuracy: 0.6575\n",
      "Epoch 420 | Train Loss: 1.030 | Train Accuracy: 0.7877 | Val Loss: 1.184 | Val Accuracy: 0.7503\n",
      "Epoch 430 | Train Loss: 1.032 | Train Accuracy: 0.7907 | Val Loss: 1.173 | Val Accuracy: 0.7793\n",
      "Epoch 440 | Train Loss: 1.028 | Train Accuracy: 0.7861 | Val Loss: 1.189 | Val Accuracy: 0.7211\n",
      "Epoch 450 | Train Loss: 1.028 | Train Accuracy: 0.8137 | Val Loss: 1.210 | Val Accuracy: 0.6919\n",
      "Epoch 460 | Train Loss: 1.036 | Train Accuracy: 0.7724 | Val Loss: 1.176 | Val Accuracy: 0.7726\n",
      "Epoch 470 | Train Loss: 1.036 | Train Accuracy: 0.8114 | Val Loss: 1.217 | Val Accuracy: 0.7242\n",
      "Epoch 480 | Train Loss: 1.024 | Train Accuracy: 0.8079 | Val Loss: 1.197 | Val Accuracy: 0.7341\n",
      "Epoch 490 | Train Loss: 1.031 | Train Accuracy: 0.7909 | Val Loss: 1.202 | Val Accuracy: 0.7397\n",
      "Epoch 500 | Train Loss: 1.028 | Train Accuracy: 0.7837 | Val Loss: 1.207 | Val Accuracy: 0.7831\n",
      "Epoch 510 | Train Loss: 1.033 | Train Accuracy: 0.7662 | Val Loss: 1.206 | Val Accuracy: 0.7322\n",
      "Epoch 520 | Train Loss: 1.026 | Train Accuracy: 0.8107 | Val Loss: 1.230 | Val Accuracy: 0.6427\n",
      "Epoch 530 | Train Loss: 1.026 | Train Accuracy: 0.7981 | Val Loss: 1.263 | Val Accuracy: 0.7820\n",
      "Epoch 540 | Train Loss: 1.041 | Train Accuracy: 0.7856 | Val Loss: 1.285 | Val Accuracy: 0.6136\n",
      "Epoch 550 | Train Loss: 1.029 | Train Accuracy: 0.7658 | Val Loss: 1.246 | Val Accuracy: 0.7799\n",
      "Epoch 560 | Train Loss: 1.019 | Train Accuracy: 0.7878 | Val Loss: 1.224 | Val Accuracy: 0.7497\n",
      "Epoch 570 | Train Loss: 1.010 | Train Accuracy: 0.7900 | Val Loss: 1.251 | Val Accuracy: 0.7575\n",
      "Epoch 580 | Train Loss: 1.016 | Train Accuracy: 0.7915 | Val Loss: 1.262 | Val Accuracy: 0.7015\n",
      "Epoch 590 | Train Loss: 1.033 | Train Accuracy: 0.7874 | Val Loss: 1.269 | Val Accuracy: 0.7226\n",
      "Epoch 600 | Train Loss: 1.017 | Train Accuracy: 0.7885 | Val Loss: 1.272 | Val Accuracy: 0.7511\n",
      "Epoch 610 | Train Loss: 1.027 | Train Accuracy: 0.7844 | Val Loss: 1.262 | Val Accuracy: 0.7096\n",
      "Epoch 620 | Train Loss: 0.995 | Train Accuracy: 0.7963 | Val Loss: 1.298 | Val Accuracy: 0.7209\n",
      "Epoch 630 | Train Loss: 1.015 | Train Accuracy: 0.7624 | Val Loss: 1.310 | Val Accuracy: 0.7604\n",
      "Epoch 640 | Train Loss: 1.011 | Train Accuracy: 0.8010 | Val Loss: 1.301 | Val Accuracy: 0.6927\n",
      "Epoch 650 | Train Loss: 1.014 | Train Accuracy: 0.7997 | Val Loss: 1.324 | Val Accuracy: 0.6505\n",
      "Epoch 660 | Train Loss: 0.999 | Train Accuracy: 0.8041 | Val Loss: 1.315 | Val Accuracy: 0.7154\n",
      "Epoch 670 | Train Loss: 1.002 | Train Accuracy: 0.7715 | Val Loss: 1.321 | Val Accuracy: 0.7488\n",
      "Epoch 680 | Train Loss: 1.003 | Train Accuracy: 0.7922 | Val Loss: 1.323 | Val Accuracy: 0.7718\n",
      "Epoch 690 | Train Loss: 1.017 | Train Accuracy: 0.7872 | Val Loss: 1.336 | Val Accuracy: 0.7719\n",
      "Epoch 700 | Train Loss: 1.003 | Train Accuracy: 0.7954 | Val Loss: 1.332 | Val Accuracy: 0.7266\n",
      "Epoch 710 | Train Loss: 0.998 | Train Accuracy: 0.8044 | Val Loss: 1.377 | Val Accuracy: 0.6942\n",
      "Epoch 720 | Train Loss: 1.003 | Train Accuracy: 0.7826 | Val Loss: 1.356 | Val Accuracy: 0.7337\n",
      "Epoch 730 | Train Loss: 1.018 | Train Accuracy: 0.7883 | Val Loss: 1.369 | Val Accuracy: 0.7554\n",
      "Epoch 740 | Train Loss: 1.012 | Train Accuracy: 0.8059 | Val Loss: 1.388 | Val Accuracy: 0.6585\n",
      "Epoch 750 | Train Loss: 1.000 | Train Accuracy: 0.7711 | Val Loss: 1.400 | Val Accuracy: 0.7662\n",
      "Epoch 760 | Train Loss: 1.005 | Train Accuracy: 0.7794 | Val Loss: 1.381 | Val Accuracy: 0.7731\n",
      "Epoch 770 | Train Loss: 1.000 | Train Accuracy: 0.7791 | Val Loss: 1.380 | Val Accuracy: 0.7731\n",
      "Epoch 780 | Train Loss: 1.001 | Train Accuracy: 0.7858 | Val Loss: 1.388 | Val Accuracy: 0.7426\n",
      "Epoch 790 | Train Loss: 1.027 | Train Accuracy: 0.7821 | Val Loss: 1.407 | Val Accuracy: 0.7289\n",
      "Epoch 800 | Train Loss: 0.990 | Train Accuracy: 0.8131 | Val Loss: 1.408 | Val Accuracy: 0.7145\n",
      "Epoch 810 | Train Loss: 0.999 | Train Accuracy: 0.7948 | Val Loss: 1.399 | Val Accuracy: 0.7097\n",
      "Epoch 820 | Train Loss: 0.992 | Train Accuracy: 0.8046 | Val Loss: 1.406 | Val Accuracy: 0.6690\n",
      "Epoch 830 | Train Loss: 1.012 | Train Accuracy: 0.8082 | Val Loss: 1.433 | Val Accuracy: 0.7338\n",
      "Epoch 840 | Train Loss: 1.007 | Train Accuracy: 0.7990 | Val Loss: 1.426 | Val Accuracy: 0.7027\n",
      "Epoch 850 | Train Loss: 1.005 | Train Accuracy: 0.7836 | Val Loss: 1.437 | Val Accuracy: 0.7471\n",
      "Epoch 860 | Train Loss: 0.994 | Train Accuracy: 0.7982 | Val Loss: 1.410 | Val Accuracy: 0.7559\n",
      "Epoch 870 | Train Loss: 1.006 | Train Accuracy: 0.7823 | Val Loss: 1.453 | Val Accuracy: 0.7699\n",
      "Epoch 880 | Train Loss: 0.992 | Train Accuracy: 0.7905 | Val Loss: 1.452 | Val Accuracy: 0.7745\n",
      "Epoch 890 | Train Loss: 0.993 | Train Accuracy: 0.7799 | Val Loss: 1.431 | Val Accuracy: 0.7503\n",
      "Epoch 900 | Train Loss: 0.998 | Train Accuracy: 0.7837 | Val Loss: 1.406 | Val Accuracy: 0.7053\n",
      "Epoch 910 | Train Loss: 0.996 | Train Accuracy: 0.7960 | Val Loss: 1.446 | Val Accuracy: 0.6740\n",
      "Epoch 920 | Train Loss: 0.987 | Train Accuracy: 0.7878 | Val Loss: 1.466 | Val Accuracy: 0.7343\n",
      "Epoch 930 | Train Loss: 1.015 | Train Accuracy: 0.7963 | Val Loss: 1.487 | Val Accuracy: 0.6896\n",
      "Epoch 940 | Train Loss: 0.996 | Train Accuracy: 0.7864 | Val Loss: 1.457 | Val Accuracy: 0.7100\n",
      "Epoch 950 | Train Loss: 0.989 | Train Accuracy: 0.7720 | Val Loss: 1.485 | Val Accuracy: 0.7695\n",
      "Epoch 960 | Train Loss: 0.988 | Train Accuracy: 0.7854 | Val Loss: 1.469 | Val Accuracy: 0.7112\n",
      "Epoch 970 | Train Loss: 0.999 | Train Accuracy: 0.7919 | Val Loss: 1.507 | Val Accuracy: 0.7195\n",
      "Epoch 980 | Train Loss: 0.992 | Train Accuracy: 0.7962 | Val Loss: 1.447 | Val Accuracy: 0.7197\n",
      "Epoch 990 | Train Loss: 0.997 | Train Accuracy: 0.8075 | Val Loss: 1.533 | Val Accuracy: 0.6635\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = GCN(num_features=4, num_classes=4).to(\"cuda\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "writer = SummaryWriter(\"runs/c0_03__s1000\")\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(\"cuda\")\n",
    "        out = model(batch)\n",
    "\n",
    "        loss = F.nll_loss(out, batch.y.to(torch.long), weight=weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        total_correct += (predicted == batch.y.to(torch.long)).sum().item()\n",
    "        total_samples += batch.y.size(0)\n",
    "\n",
    "    train_accuracy = total_correct / total_samples\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_total_correct = 0\n",
    "    val_total_samples = 0\n",
    "    val_total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "            val_batch = val_batch.to(\"cuda\")\n",
    "            val_out = model(val_batch)\n",
    "\n",
    "            val_loss = F.nll_loss(val_out, val_batch.y.to(torch.long), weight=weights)\n",
    "            val_total_loss += val_loss.item()\n",
    "\n",
    "            _, val_predicted = torch.max(val_out, 1)\n",
    "            val_total_correct += (\n",
    "                (val_predicted == val_batch.y.to(torch.long)).sum().item()\n",
    "            )\n",
    "            val_total_samples += val_batch.y.size(0)\n",
    "\n",
    "    val_accuracy = val_total_correct / val_total_samples\n",
    "\n",
    "    writer.add_scalar(\"Loss/train\", total_loss / len(train_loader), epoch)\n",
    "    writer.add_scalar(\"Accuracy/train\", train_accuracy, epoch)\n",
    "    writer.add_scalar(\"Loss/val\", val_total_loss / len(val_loader), epoch)\n",
    "    writer.add_scalar(\"Accuracy/val\", val_accuracy, epoch)\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        # print(f'Saved the best model with validation accuracy: {best_val_accuracy:.4f}')\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch} | Train Loss: {total_loss / len(train_loader):.3f} | Train Accuracy: {train_accuracy:.4f} | Val Loss: {val_total_loss / len(val_loader):.3f} | Val Accuracy: {val_accuracy:.4f}\"\n",
    "        )\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[3329, 4], edge_index=[2, 66839], edge_attr=[66839, 1], y=[3329], batch=[3329], ptr=[5])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(dataloader)).to(\"cuda\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0,\n",
       "        3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0,\n",
       "        3, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 1, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 3,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "        0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0,\n",
       "        0, 1, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test(sample).argmax(dim=1).detach().to(\"cpu\")[0:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 3., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 3., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.y[0: 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_classwise_acc(true_labels, predicted_labels):\n",
    "    # true_labels, predicted_labels = sample.y.detach().to(\"cpu\"), model_test(sample).argmax(dim=1).detach().to(\"cpu\")\n",
    "\n",
    "    true_positives = {}\n",
    "    total_samples = {}\n",
    "\n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        if true.item() in total_samples:\n",
    "            total_samples[true.item()] += 1\n",
    "        else:\n",
    "            total_samples[true.item()] = 1\n",
    "\n",
    "        if true == pred:\n",
    "            if true.item() in true_positives:\n",
    "                true_positives[true.item()] += 1\n",
    "            else:\n",
    "                true_positives[true.item()] = 1\n",
    "\n",
    "    # Calculate class-wise accuracy\n",
    "    class_wise_accuracy = {}\n",
    "    for cls in total_samples:\n",
    "        if cls in true_positives:\n",
    "            class_wise_accuracy[cls] = true_positives[cls] / total_samples[cls]\n",
    "        else:\n",
    "            class_wise_accuracy[cls] = 0.0  # No true positives for this class\n",
    "\n",
    "    print(\"Class-wise Accuracy:\", class_wise_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_sample = torch.load(\"../../data/processed/validation/008.pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0,\n",
       "        2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
       "        2, 0, 0, 0, 2, 1, 0, 0, 2, 2, 1, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2,\n",
       "        2, 1, 1, 1, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2,\n",
       "        2, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 0, 2, 3, 2, 2, 0, 0, 0,\n",
       "        2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 2, 2, 1, 2, 2, 0, 0, 0, 3, 0,\n",
       "        2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "        0, 1, 1, 2, 0, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 2, 0,\n",
       "        0, 2, 2, 2, 2, 1, 1, 2, 0, 1, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 3, 0, 0, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0,\n",
       "        0, 0, 3, 0, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2,\n",
       "        0, 0, 2, 2, 3, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 2, 1, 3,\n",
       "        0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 2, 1, 0, 2, 2, 0, 2, 2, 0, 0, 0, 3, 0, 3, 2, 2, 0, 0, 0, 0, 0,\n",
       "        0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 1, 0, 0,\n",
       "        0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 2,\n",
       "        0, 2, 0, 2, 0, 2, 0, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0,\n",
       "        2, 3, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 2,\n",
       "        2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 2, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0,\n",
       "        2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 3, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 2, 0,\n",
       "        2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "        0, 0, 0, 0, 3, 0, 2, 2, 2, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0,\n",
       "        1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0,\n",
       "        0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "        0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0,\n",
       "        1, 3, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2,\n",
       "        0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2,\n",
       "        0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test(validation_sample).detach().cpu().argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "350*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[819, 4], edge_index=[2, 16479], edge_attr=[16479, 1], y=[819])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation = torch.load(\"../../data/processed/008.pt\")\n",
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-wise Accuracy: {0.0: 0.6824408468244084, 2.0: 0.6666666666666666, 3.0: 0.0}\n"
     ]
    }
   ],
   "source": [
    "get_classwise_acc(validation.y, model_test(validation.to(\"cuda\")).argmax(dim=1))\n",
    "\n",
    "# reminder {1:necrotic, 2: edema, 3:enhancing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 2., 2., 2., 0., 3.,\n",
       "        0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 0., 0., 0., 0., 0.,\n",
       "        2., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 2., 0., 3., 2., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 2., 2., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        2., 0., 0., 0., 0., 0., 0., 0., 0., 2., 2., 3., 0., 2., 0., 2., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        2., 0., 0., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.load(\"../../data/processed/0_05__1000/007.pt\").to(\"cuda\")\n",
    "t.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-wise Accuracy: [0.6886675       nan 0.2       0.       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66121/2201379399.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  class_wise_accuracy = cm.diagonal() / cm.sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "true_labels, predicted_labels = validation.y.detach().cpu(), model_test(validation.to(\"cuda\")).argmax(dim=1).detach().cpu()\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "class_wise_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "print(\"Class-wise Accuracy:\", class_wise_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[855, 4], edge_index=[2, 16073], edge_attr=[16073, 1], y=[855])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"../../data/processed/0_05__1000/003.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_generation as g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: 'data/raw/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t1.nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/thesis/venv/lib/python3.10/site-packages/nibabel/loadsave.py:100\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/raw/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t1.nii'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nii_loader \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNii_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/thesis/src/main/graph_generation.py:59\u001b[0m, in \u001b[0;36mNii_loader.__init__\u001b[0;34m(self, file_id, root_dir)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaths_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt1\u001b[39m\u001b[38;5;124m\"\u001b[39m: t1_path,\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt1ce\u001b[39m\u001b[38;5;124m\"\u001b[39m: t1ce_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m: mask_path,\n\u001b[1;32m     56\u001b[0m }\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaths_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_fdata())\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# self.t1 = [x for x in nib.load(list(self.paths_dict.values())).get_fdata()]\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[0;32m~/projects/thesis/venv/lib/python3.10/site-packages/nibabel/loadsave.py:102\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_result\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: 'data/raw/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t1.nii'"
     ]
    }
   ],
   "source": [
    "nii_loader = g.Nii_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_supervoxels(filename: str):\n",
    "    with open(filename, 'rb') as f:\n",
    "        list_of_supervoxels = pickle.load(f)\n",
    "    return list_of_supervoxels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_generation import SuperVoxel, Voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../pickleGraphTest.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[43mload_supervoxels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../pickleGraphTest.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m, in \u001b[0;36mload_supervoxels\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_supervoxels\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m         list_of_supervoxels \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m list_of_supervoxels\n",
      "File \u001b[0;32m~/projects/thesis/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../pickleGraphTest.pkl'"
     ]
    }
   ],
   "source": [
    "l = load_supervoxels(\"../../pickleGraphTest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1276\n",
      "drwxr-xr-x 10 tryfonm tryfonm   4096 May 25 04:51 .\n",
      "drwxr-xr-x 41 tryfonm tryfonm   4096 Apr 27 17:30 ..\n",
      "drwxr-xr-x  8 tryfonm tryfonm   4096 May 23 02:48 .git\n",
      "-rw-r--r--  1 tryfonm tryfonm     93 Feb 12 00:07 .gitignore\n",
      "-rw-r--r--  1 tryfonm tryfonm    725 Dec  1 22:12 Makefile\n",
      "drwxr-xr-x  2 tryfonm tryfonm   4096 May  7 16:51 backup\n",
      "drwxr-xr-x  4 tryfonm tryfonm   4096 May 23 22:40 data\n",
      "drwxr-xr-x  2 tryfonm tryfonm   4096 Feb 23 13:35 models\n",
      "drwxr-xr-x  4 tryfonm tryfonm   4096 May 23 21:49 notebooks\n",
      "-rw-r--r--  1 tryfonm tryfonm    233 May 10 16:23 notes\n",
      "-rw-r--r--  1 tryfonm tryfonm 817680 May 25 04:51 pickleGraphTest.py\n",
      "-rw-r--r--  1 tryfonm tryfonm   1624 Nov 19  2023 requirements_backup.txt\n",
      "drwxr-xr-x  3 tryfonm tryfonm   4096 Dec  1 22:12 runs\n",
      "-rw-r--r--  1 tryfonm tryfonm    901 Apr  5 10:27 sista_error\n",
      "-rw-r--r--  1 tryfonm tryfonm 423376 May 23 22:31 someRandomGraph.pt\n",
      "drwxr-xr-x  4 tryfonm tryfonm   4096 Nov 19  2023 src\n",
      "drwxr-xr-x  7 tryfonm tryfonm   4096 Nov 19  2023 venv\n"
     ]
    }
   ],
   "source": [
    "!ls -la ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.zeros_like(torch.tensor(sample_image))\n",
    "for sv_index, sv in enumerate(list_of_supervoxels):\n",
    "    indices = tuple(zip(*sv.list_of_voxel_indices))\n",
    "    predictions[indices] = predicted_labels[sv_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
